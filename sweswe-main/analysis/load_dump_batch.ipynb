{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/minimax-dialogue/users/xiancai/verl')\n",
    "import pickle\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/minimax-dialogue/users/xiancai/hf_models/R2EGym-32B-Agent')\n",
    "\n",
    "def load_from_disk(filepath) -> 'DataProto':\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "batch = load_from_disk('/minimax-dialogue/users/xiancai/verl/sample_log/j-yhdv3fepym/batch_0001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_init__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'batch',\n",
       " 'check_consistency',\n",
       " 'chunk',\n",
       " 'concat',\n",
       " 'from_dict',\n",
       " 'from_single_dict',\n",
       " 'load_from_disk',\n",
       " 'make_iterator',\n",
       " 'meta_info',\n",
       " 'non_tensor_batch',\n",
       " 'pop',\n",
       " 'print_size',\n",
       " 'rename',\n",
       " 'reorder',\n",
       " 'repeat',\n",
       " 'save_to_disk',\n",
       " 'select',\n",
       " 'select_idxs',\n",
       " 'slice',\n",
       " 'to',\n",
       " 'union']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_StringKeys(dict_keys(['prompts', 'responses', 'response_mask', 'input_ids', 'attention_mask', 'position_ids', 'old_log_probs', 'entropys', 'ref_log_prob', 'token_level_scores', 'token_level_rewards', 'advantages', 'returns']))\n"
     ]
    }
   ],
   "source": [
    "print(batch.batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6400)\n",
      "tensor(0.1835)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "entropy_list = batch.batch['entropys'][0]\n",
    "token_list = batch.batch['responses'][0]\n",
    "# token_list = [tokenizer.convert_ids_to_tokens(token) for token in token_list]\n",
    "\n",
    "# assert len(entropy_list) == len(token_list)\n",
    "# for entropy, token in zip(entropy_list, token_list):\n",
    "#     print(entropy, token)\n",
    "\n",
    "response_mask = batch.batch['response_mask'][0]\n",
    "# compute average entropy of the masked tokens\n",
    "# masked_entropy_list = [entropy for entropy, mask in zip(entropy_list, response_mask) if mask]\n",
    "# print(sum(masked_entropy_list) / len(masked_entropy_list))\n",
    "\n",
    "# not_masked_entropy_list = [entropy for entropy, mask in zip(entropy_list, response_mask) if not mask]\n",
    "# print(sum(not_masked_entropy_list) / len(not_masked_entropy_list))\n",
    "max_response_length = batch.batch['responses'].shape[-1]\n",
    "loss_mask = batch.batch['attention_mask'][:, -max_response_length:][0]\n",
    "\n",
    "print((entropy_list * loss_mask).sum() / (loss_mask.sum() + 1e-8))\n",
    "print((entropy_list * response_mask).sum() / (response_mask.sum() + 1e-8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.batch['old_log_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.batch['token_level_rewards'].sum(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/minimax-dialogue/users/xiancai/hf_models/R2EGym-32B-Agent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = batch.batch\n",
    "responses = data['responses']\n",
    "\n",
    "# print response_length each\n",
    "max_response_length = batch.batch['responses'].shape[-1]\n",
    "\n",
    "response_length = batch.batch['attention_mask'][:, -max_response_length:].sum(-1)\n",
    "# response_length = responses.size(1)\n",
    "# print the data if response_length > 32768\n",
    "long_response_indices = (response_length > 32768).nonzero()\n",
    "\n",
    "for idx in long_response_indices:\n",
    "    response_ids = responses[idx].tolist()[0]\n",
    "    print(response_ids)\n",
    "    response = tokenizer.decode(response_ids)\n",
    "    print(response)\n",
    "\n",
    "\n",
    "# print(f\"Number of samples with response_length > 32768: {len(long_response_indices)}\")\n",
    "\n",
    "# attention_mask = data['attention_mask']\n",
    "# response_mask = data['response_mask']\n",
    "# old_log_prob = data['old_log_probs']\n",
    "# advantages = data['advantages']\n",
    "# rewards = data['token_level_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_response_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_response_with_ansi_colors(response_ids, response_mask, color_type=\"yellow\"):\n",
    "    \"\"\"\n",
    "    使用ANSI颜色代码为response添加彩色背景高亮\n",
    "    \n",
    "    Args:\n",
    "        response_text: 解码后的response文本\n",
    "        response_mask: 布尔mask，标记需要高亮的token位置\n",
    "        color_type: 颜色类型 (\"yellow\", \"red\", \"green\", \"blue\", \"cyan\", \"magenta\")\n",
    "    \"\"\"\n",
    "    # ANSI颜色代码映射\n",
    "    color_codes = {\n",
    "        \"yellow\": \"\\033[43m\",     # 黄色背景\n",
    "        \"red\": \"\\033[41m\",        # 红色背景\n",
    "        \"green\": \"\\033[42m\",      # 绿色背景\n",
    "        \"blue\": \"\\033[44m\",       # 蓝色背景\n",
    "        \"cyan\": \"\\033[46m\",       # 青色背景\n",
    "        \"magenta\": \"\\033[45m\",    # 洋红色背景\n",
    "        \"white\": \"\\033[47m\",      # 白色背景\n",
    "    }\n",
    "    \n",
    "    HIGHLIGHT = color_codes.get(color_type, color_codes[\"yellow\"])\n",
    "    RESET = \"\\033[0m\"  # 重置颜色\n",
    "    \n",
    "    # 如果mask长度与文本长度不匹配，需要进行token级别的处理\n",
    "    if len(response_mask) != len(response_ids):\n",
    "        return highlight_tokens_with_ansi(response_ids, response_mask, HIGHLIGHT, RESET)\n",
    "    \n",
    "    result = []\n",
    "    in_highlight = False\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(response_ids)\n",
    "    for i, char in enumerate(tokens):\n",
    "        if response_mask[i] and not in_highlight:\n",
    "            result.append(HIGHLIGHT)\n",
    "            in_highlight = True\n",
    "        elif not response_mask[i] and in_highlight:\n",
    "            result.append(RESET)\n",
    "            in_highlight = False\n",
    "        \n",
    "        result.append(char)\n",
    "    \n",
    "    if in_highlight:\n",
    "        result.append(RESET)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "def highlight_tokens_with_ansi(token_ids, token_mask, highlight_code, reset_code):\n",
    "    \"\"\"处理token级别的高亮\"\"\"\n",
    "    # 这里需要根据您的tokenizer进行token分割\n",
    "    # 假设使用空格分割（您可能需要根据实际情况调整）\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    print(tokens)\n",
    "\n",
    "    \n",
    "    if len(tokens) != len(token_mask):\n",
    "        print(f\"警告: tokens长度({len(tokens)})与mask长度({len(token_mask)})不匹配\")\n",
    "        return \"\".join(tokens)\n",
    "    \n",
    "    highlighted_tokens = []\n",
    "    for token, should_highlight in zip(tokens, token_mask):\n",
    "        if should_highlight:\n",
    "            highlighted_tokens.append(f\"{highlight_code}{token}{reset_code}\")\n",
    "        else:\n",
    "            highlighted_tokens.append(token)\n",
    "    \n",
    "    return \" \".join(highlighted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in long_response_indices:\n",
    "    response_ids = responses[idx].tolist()[0]\n",
    "    response_mask = data['response_mask'][idx].tolist()[0]\n",
    "    print(len(response_ids))\n",
    "    print(sum(response_mask))\n",
    "    print(response_ids)\n",
    "    print(response_mask)\n",
    "    print(tokenizer.convert_ids_to_tokens(response_ids))\n",
    "\n",
    "    # response = tokenizer.decode(response_ids)\n",
    "    # ANSI高亮测试\n",
    "    ansi_result = highlight_response_with_ansi_colors(response_ids, response_mask, \"red\")\n",
    "\n",
    "    # 保存测试文件\n",
    "    with open(\"test_ansi.ans\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(ansi_result)\n",
    "\n",
    "    print(\"测试文件已保存: test_ansi.ans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sequence_score = batch.batch['token_level_scores'].sum(-1)\n",
    "sequence_reward = batch.batch['token_level_rewards'].sum(-1)\n",
    "\n",
    "advantages = batch.batch['advantages']\n",
    "returns = batch.batch['returns']\n",
    "\n",
    "max_response_length = batch.batch['responses'].shape[-1]\n",
    "\n",
    "prompt_mask = batch.batch['attention_mask'][:, :-max_response_length].bool()\n",
    "response_mask = batch.batch['attention_mask'][:, -max_response_length:].bool()\n",
    "\n",
    "max_prompt_length = prompt_mask.size(-1)\n",
    "\n",
    "# response_info = _compute_response_info(batch)\n",
    "# prompt_length = response_info['prompt_length']\n",
    "# response_length = response_info['response_length']\n",
    "\n",
    "valid_adv = torch.masked_select(advantages, response_mask)\n",
    "valid_returns = torch.masked_select(returns, response_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = data['log_probs']\n",
    "print(log_probs)\n",
    "print(old_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = batch.batch['token_level_scores'].sum(-1)\n",
    "l = batch.batch['token_level_rewards'].sum(-1)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.batch['token_level_rewards'][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.load('/data/minimax-dialogue/users/yuelan/repos/verl/a.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
